# ğŸ§© Projeto Re-LETRA: Sons que Constroem Palavras

## ğŸŒ Contexto
Ainda hÃ¡ uma lacuna grave: nÃ£o existe aplicativo que trabalhe **consciÃªncia fonolÃ³gica para adolescentes e adultos com dislexia severa**, voltado Ã  **autonomia, autoestima e acessibilidade real**.

A proposta do **Re-LETRA** Ã© preencher essa lacuna criando um sistema interativo que converte som em aprendizado tangÃ­vel â€” transformando a fala em compreensÃ£o escrita.

---

## ğŸ¯ Objetivos
- Desenvolver um **aplicativo inclusivo** que trabalhe a consciÃªncia fonolÃ³gica de forma interativa.  
- Promover **autonomia e autoestima** em pessoas com dificuldade severa de leitura.  
- Garantir **acessibilidade real**, com interface nÃ£o infantilizada.

---

## ğŸ§© Estrutura do projeto

| Etapa | Foco | EntregÃ¡vel |
|-------|------|------------|
| Etapa 1 | Planejamento pedagÃ³gico e cientÃ­fico | Objetivos, teorias base, equipe |
| Etapa 2 | Desenvolvimento tÃ©cnico | App + IA de fala |
| Etapa 3 | Design inclusivo e acessibilidade | Interface validada |
| Etapa 4 | Testes e validaÃ§Ã£o | Feedback com usuÃ¡rios reais |
| Etapa 5 | AplicaÃ§Ã£o em escolas | Manual do educador |
| Etapa 6 | ExpansÃ£o e monetizaÃ§Ã£o | VersÃ£o pÃºblica e parcerias |

---

## ğŸ§  Base teÃ³rica
- **Modelo de Desenvolvimento FonolÃ³gico (Goswami)**
- **MSLE â€“ Multisensory Structured Language Education**
- **BNCC e Diretrizes da EducaÃ§Ã£o Especial**

---

## âš™ï¸ Stack tÃ©cnica
| Componente | Tecnologia sugerida |
|-------------|--------------------|
| IA de fala | Whisper / Coqui STT |
| Machine Learning | TensorFlow / PyTorch |
| Interface | Flutter ou React Native |
| Backend | Python (FastAPI) |
| Banco de dados | SQLite ou Firebase |
| IntegraÃ§Ã£o multimodal | Kivy, Pygame ou Unity (C#) |

---

## ğŸ”Š Funcionalidades principais
- IdentificaÃ§Ã£o de fonemas isolados.  
- Jogos de associaÃ§Ã£o fonema/letra.  
- RepetiÃ§Ã£o guiada de sÃ­labas e rimas.  
- Feedback auditivo adaptativo.  
- Painel de progresso do aluno.  
- Modo tutor/mediador para educadores.

---

## ğŸ§  AvaliaÃ§Ã£o e IA
O app deve avaliar:
1. **PronÃºncia correta** de fonemas.  
2. **CoerÃªncia fonolÃ³gica** entre som e grafia.  
3. **FluÃªncia temporal** e consistÃªncia na fala.

**KPI principal:** Taxa de CoerÃªncia â‰¥ 0.7  
(MÃ©dia de similaridade entre som e texto esperado.)

---

## ğŸ§© Design e UX
- Ãcones grandes, contraste alto.  
- Pouco texto, foco em **sÃ­mbolos e som**.  
- Tons sÃ³brios: azul marinho, verde escuro, laranja queimado.  
- Avatares simples, nÃ£o infantis.  
- Feedback visual sutil (ondas, barras de progresso).

---

## ğŸ§ª ValidaÃ§Ã£o
1. Testar com grupos pequenos (dislexia severa).  
2. Coletar mÃ©tricas de engajamento e acerto.  
3. Ajustar com especialistas em TDAH/TEA.  
4. Reavaliar latÃªncia e acessibilidade.

---

## ğŸ“Š Riscos e modos de falha
| Risco | Impacto | Probabilidade |
|--------|----------|---------------|
| STT erra por sotaque/ruÃ­do | Alto | MÃ©dio |
| LatÃªncia em tempo real | MÃ©dio | Alto |
| Interface complexa | Alto | MÃ©dio |
| Falta de adesÃ£o escolar | Alto | Baixo |

---

## ğŸ’¡ Alternativa experimental
VersÃ£o hÃ­brida: unir o *karaokÃª de coerÃªncia* (voz â†’ texto â†’ coerÃªncia) com o mÃ³dulo de **consciÃªncia fonolÃ³gica**, avaliando simultaneamente:
- Sentido do que Ã© dito;
- Clareza fonÃªmica.

Falha provÃ¡vel: custo alto de processamento e ruÃ­do semÃ¢ntico.

---

## ğŸ”— PrÃ³ximos passos
**Imediato (2â€“7 dias):**
- Criar wireframe bÃ¡sico (telas essenciais)
- Testar STT local
- Mapear fluxo de usuÃ¡rio no Canvas

**TÃ¡tico (2â€“8 semanas):**
- Implementar IA de fonemas + semÃ¢ntica
- Criar protÃ³tipo navegÃ¡vel
- Testar com pÃºblico real

---

## ğŸ“š ReferÃªncias
- Goswami, U. (2000). *Phonological development and reading by analogy.*
- Shaywitz, S. (2003). *Overcoming Dyslexia.*
- BNCC â€“ EducaÃ§Ã£o Especial.
